{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсер CIAN.RU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Путь к рабочей папке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path().absolute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже собраны все регулярные выражения для поиска переменных в HTML-коде (для удобства обновления в случае их динамического изменения на стороне сервера)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_dict = {\n",
    "    'offersData':\"(?<=\\\"offers\\\":\\[)(.*)(?=\\],\\\"aggregatedOffers\\\")\",     \n",
    "    'fullUrl':\"(?<=fullUrl\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'cianId':\"(?<=ru\\\\u002Fsale\\\\u002Fflat\\\\u002F)(.*?)(?=\\\\u002F\\\",)\",\n",
    "#     'photoUrl':\"(?<=fullUrl\\\":\\\")(.*?)(?=\\\",)\", # большой размер - 1\n",
    "#     'photoUrl':\"(?<=thumbnail2Url\\\":\\\")(.*?)(?=\\\",)\", # средний размер - 4 \n",
    "    'photoUrl':\"(?<=thumbnailUrl\\\":\\\")(.*?)(?=\\\",)\", # маленький размер - 2\n",
    "    'totalOffers':\"(?<=totalOffers\\\":)(.*?)(?=\\,)\",\n",
    "    'description':\"(?<=\\\"description\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'totalArea':\"(?<=\\\"totalArea\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'loggiasCount':\"(?<=loggiasCount\\\":)(.*?)(?=,)\",\n",
    "    'flatType':\"(?<=flatType\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'kitchenArea':\"(?<=kitchenArea\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'undergrounds':\"(?<=undergrounds\\\":\\[)(.*?)(?=])\",\n",
    "    'transport_time':\"(?<=time\\\":)(.*?)(?=,)\",\n",
    "    'station_name':\"(?<=name\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'transportType':\"(?<=transportType\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'coord_lat':\"(?<=lat\\\":)(.*?)(?=,)\",\n",
    "    'coord_lng':\"(?<=lng\\\":)(.*?)(?=,)\",\n",
    "    'location':\"(?<=location\\\",\\\"name\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'okrug':\"(?<=okrug\\\",\\\"name\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'raion':\"(?<=raion\\\",\\\"name\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'street':\"(?<=street\\\",\\\"name\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'house':\"(?<=house\\\",\\\"name\\\":\\\")(.*?)(?=\\\",)\",\n",
    "    'isApartments':\"(?<=isApartments\\\":)(.*?)(?=,)\",\n",
    "    'creationDate':\"(?<=creationDate\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'status':\"(?<=status\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'floorNumber':\"(?<=\\\"floorNumber\\\":)(.*?)(?=,)\",\n",
    "    'addedTimestamp':\"(?<=\\\"addedTimestamp\\\":)(.*?)(?=,)\",\n",
    "    'livingArea':\"(?<=livingArea\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'materialType':\"(?<=materialType\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'buildYear':\"(?<=\\\"buildYear\\\":)(.*?)(?=,)\",\n",
    "    'passengerLiftsCount':\"(?<=\\\"passengerLiftsCount\\\":)(.*?)(?=,)\",\n",
    "    'floorsCount':\"(?<=\\\"floorsCount\\\":)(.*?)(?=,)\",\n",
    "    'year':\"(?<=\\\"year\\\":)(.*?)(?=,)\",\n",
    "    'isComplete':\"(?<=\\\"isComplete\\\":)(.*?)(?=,)\",\n",
    "    'cargoLiftsCount':\"(?<=\\\"cargoLiftsCount\\\":)(.*?)(?=,)\",\n",
    "    'roomsCount':\"(?<=\\\"roomsCount\\\":)(.*?)(?=,)\",\n",
    "    'price':\"(?<=\\\"price\\\":)(.*?)(?=,)\",\n",
    "    'mortgageAllowed':\"(?<=\\\"mortgageAllowed\\\":)(.*?)(?=,)\",\n",
    "    'currency':\"(?<=\\\"currency\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'accountType':\"(?<=\\\"accountType\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'agencyName':\"(?<=\\\"agencyName\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'cianProfileStatus':\"(?<=\\\"cianProfileStatus\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'cianUserId':\"(?<=\\\"cianUserId\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'companyName':\"(?<=\\\"companyName\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'isAgent':\"(?<=\\\"isAgent\\\":)(.*?)(?=,)\",\n",
    "    'isBuilder':\"(?<=\\\"isBuilder\\\":)(.*?)(?=,)\",\n",
    "    'isPassportVerified':\"(?<=\\\"isPassportVerified\\\":)(.*?)(?=,)\",\n",
    "    'isSelfEmployed':\"(?<=\\\"isSelfEmployed\\\":)(.*?)(?=,)\",\n",
    "    'isSubAgent':\"(?<=\\\"isSubAgent\\\":)(.*?)(?=,)\",\n",
    "    'userTrustLevel':\"(?<=\\\"userTrustLevel\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'userId':\"(?<=\\\"userId\\\":)(.*?)(?=,)\",\n",
    "    'userType':\"(?<=\\\"userType\\\":\\\")(.*?)(?=\\\")\",\n",
    "    'isCianPartner':\"(?<=\\\"isCianPartner\\\":)(.*?)(?=,)\",\n",
    "    'userInput':\"(?<=\\\"userInput\\\":\\\")(.*?)(?=\\\")\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_dict = {\n",
    "#     'Новомосковский административный округ':325, #округ\n",
    "        'Внуковское':328, 'Воскресенское':327, 'Десёновское':329, 'Кокошкино':330, 'Марушкинское':238, 'Московский':332,        'Мосрентген':333,        'Рязановское':334,\n",
    "        'Сосенское':335, 'Филимонковское':336, 'Щербинка':337,\n",
    "#     'Троицкий административный округ':326, #округ \n",
    "        'Вороновское':338, 'Киевский':339, 'Клёновское':340, 'Краснопахорское':341, 'Михайлово-Ярцевское':342,\n",
    "        'Новофёдоровское':343, 'Первомайское':344, 'Роговское':345, 'Троицк':346, 'Щаповское':347,\n",
    "#     'Зеленоградский административный округ':151, #округ\n",
    "        'Крюково':154, 'Матушкино':355, 'Матушкино-Савёлки':152, 'Панфиловский':153, 'Савёлки':356, 'Силино':357,\n",
    "        'Старое Крюково':358,\n",
    "#     'Северо-Западный административный округ':1, #округ\n",
    "        'Куркино':125, 'Митино':126, 'Покровское-Стрешнево':127, 'Северное Тушино':128, 'Строгино':129,\n",
    "        'Хорошево-Мневники':130, 'Щукино':131, 'Южное Тушино':132,\n",
    "#     'Западный административный округ':11, #округ\n",
    "        'Внуково':112, 'Дорогомилово':113, 'Крылатское':114, 'Кунцево':115, 'Можайский':116, 'Ново-Переделкино':117,\n",
    "        'Очаково-Матвеевское':118, 'Проспект Вернадского':119, 'Раменки':120, 'Солнцево':121, 'Тропарево-Никулино':122,\n",
    "        'Филевский парк':123, 'Фили-Давыдково':124, 'Конезавод':349, 'Рублёво-Архангельское':348, 'Сколково':350,\n",
    "#     'Юго-Западный административный округ':10, #округ\n",
    "        'Академический':100, 'Гагаринский':101, 'Зюзино':102, 'Коньково':103, 'Котловка':104, 'Ломоносовский':105,\n",
    "        'Обручевский':106, 'Северное Бутово':107, 'Теплый Стан':108, 'Черемушки':109, 'Южное Бутово':110, 'Ясенево':111,\n",
    "#     'Северный административный округ':5, #округ\n",
    "        'Аэропорт':23, 'Беговой':24, 'Бескудниковский':25, 'Войковский':26, 'Восточное Дегунино':27, 'Головинский':28,\n",
    "        'Дмитровский':29, 'Западное Дегунино':30, 'Коптево':31, 'Левобережный':32, 'Молжаниновский':33, 'Савеловский':34,\n",
    "        'Сокол':35, 'Тимирязевский':36, 'Ховрино':37, 'Хорошевский':38, \n",
    "#     'Центральный административный округ':4, #округ\n",
    "        'Арбат':13, 'Басманный':14, 'Замоскворечье':15, 'Красносельский':16, 'Мещанский':17, 'Пресненский':18, \n",
    "        'Таганский':19, 'Тверской':20, 'Хамовники':21, 'Якиманка':22, \n",
    "#     'Южный административный округ':9, #округ\n",
    "        'Бирюлево Восточное':84, 'Бирюлево Западное':85, 'Братеево':86, 'Даниловский':87, 'Донской':88, 'Зябликово':89, \n",
    "        'Москворечье-Сабурово':90, 'Нагатино-Садовники':91, 'Нагатинский затон':92, 'Нагорный':93, \n",
    "        'Орехово-Борисово Северное':94, 'Орехово-Борисово Южное':95, 'Царицыно':96, 'Чертаново Северное':97, \n",
    "        'Чертаново Центральное':98, 'Чертаново Южное':99, \n",
    "#     'Северо-Восточный административный округ':6, #округ\n",
    "        'Алексеевский':39, 'Алтуфьевский':40, 'Бабушкинский':41, 'Бибирево':42, 'Бутырский':43, 'Лианозово':44, \n",
    "        'Лосиноостровский':45, 'Марфино':46, 'Марьина роща':47, 'Останкинский':48, 'Отрадное':49, 'Ростокино':50, \n",
    "        'Свиблово':51, 'Северное Медведково':53, 'Северный':52, 'Южное Медведково':54, 'Ярославский':55, \n",
    "#     'Восточный административный округ':7, #округ\n",
    "        'Богородское':56, 'Вешняки':57, 'Восточное Измайлово':59, 'Восточный':58, 'Гольяново':60, 'Ивановское':61,\n",
    "        'Измайлово':62, 'Косино-Ухтомский':63, 'Метрогородок':64, 'Новогиреево':65, 'Новокосино':66, 'Перово':67, \n",
    "        'Преображенское':68, 'Северное Измайлово':69, 'Соколиная гора':70, 'Сокольники':71, \n",
    "#     'Юго-Восточный административный округ':8, #округ\n",
    "        'Выхино-Жулебино':72, 'Капотня':73, 'Кузьминки':74, 'Лефортово':75, 'Люблино':76, 'Марьино':77, 'Некрасовка':78, \n",
    "        'Нижегородский':79, 'Печатники':80, 'Рязанский':81, 'Текстильщики':82, 'Южнопортовый':83,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переменные, используемые в классе CianParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_districts = str(path) + '/df_districts.csv'\n",
    "file_flats = str(path) + '/df_flats.csv'\n",
    "dir_photo = 'D://cian_photo/'\n",
    "# dir_photo = 'C://cian_photo/'\n",
    "district_columns = ['id', 'district_name', 'district_type']\n",
    "\n",
    "flat_columns = [\n",
    "    'id',\n",
    "    'url',\n",
    "    'timestamp_parsed',\n",
    "    'description',\n",
    "    'total_area',\n",
    "    'loggias_count',\n",
    "    'flat_type',\n",
    "    'kitchen_area',\n",
    "    'station_name1',\n",
    "    'station_name2',\n",
    "    'station_name3',\n",
    "    'transport_type1',\n",
    "    'transport_type2',\n",
    "    'transport_type3',\n",
    "    'transport_time1',\n",
    "    'transport_time2',\n",
    "    'transport_time3',\n",
    "    'coord_lat',\n",
    "    'coord_lng',\n",
    "    'location',\n",
    "    'okrug',\n",
    "    'raion',\n",
    "    'street',\n",
    "    'house',\n",
    "    'is_apartments',\n",
    "    'creation_date',\n",
    "    'status',\n",
    "    'floor_number',\n",
    "    'added_timestamp',\n",
    "    'living_area',\n",
    "    'material_type',\n",
    "    'build_year',\n",
    "    'passenger_lifts_count',\n",
    "    'floors_count',\n",
    "    'year',\n",
    "    'is_complete',\n",
    "    'cargo_lifts_count',\n",
    "    'rooms_count',\n",
    "    'price',\n",
    "    'mortgage_allowed',\n",
    "    'currency',\n",
    "    'account_type',\n",
    "    'agency_name',\n",
    "    'cian_profile_status',\n",
    "    'cian_user_id',\n",
    "    'company_name',\n",
    "    'is_agent',\n",
    "    'is_builder',\n",
    "    'is_passport_verified',\n",
    "    'is_self_employed',\n",
    "    'is_sub_agent',\n",
    "    'user_trust_level',\n",
    "    'user_id',\n",
    "    'user_type',\n",
    "    'is_cian_partner',\n",
    "    'user_address',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_photo):\n",
    "    os.mkdir(dir_photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример полной ссылки по всем квартирам для одного конкретного района:\n",
    "\n",
    "<a href=\"https://www.cian.ru/cat.php?deal_type=sale&district[0]=112&engine_version=2&offer_type=flat&p=1&region=1&room1=1&room2=1&room3=1&room4=1&room5=1&room6=1&room7=1&room8=1&room9=1\">Квартиры в районе Внуково</a>\n",
    "\n",
    "https://www.cian.ru/cat.php?deal_type=sale&district[0]=112&engine_version=2&offer_type=flat&p=1&region=1&room1=1&room2=1&room3=1&room4=1&room5=1&room6=1&room7=1&room8=1&room9=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CianParser(): \n",
    "    \"\"\"\n",
    "    Класс парсинга данных из CIAN в pandas-датасет    \n",
    "                 regex_dict : словарь регулярных выражений для поиска переменных в HTML-коде\n",
    "                 districts : список районов, для которых парсятся предложения \n",
    "                 verbose : булевый признак отображения логов\n",
    "                 wait : целочисленное значение задержки между переходом на следующую страницу, в секундах\n",
    "                         требуется для того, чтобы не попасть на капчу\n",
    "                 file_districts : файл датасета с данными по районам\n",
    "                 file_flats : файл датасета с данными по квартирам (основной датасет)\n",
    "                 dir_photo : папка с фотографиями квартир\n",
    "                 district_columns : столбцы датасета с данными по районам\n",
    "                 flat_columns : столбцы датасета с данными по квартирам\n",
    "    \"\"\"\n",
    "    \n",
    "    # init\n",
    "    def __init__(self,\n",
    "                 regex_dict=regex_dict,\n",
    "                 districts=None, \n",
    "                 verbose=True,\n",
    "                 wait=10,\n",
    "                 file_districts=file_districts,\n",
    "                 file_flats = file_flats,\n",
    "                 dir_photo = dir_photo,\n",
    "                 district_columns = district_columns,\n",
    "                 flat_columns = flat_columns,\n",
    "                ):\n",
    "        self.regex_dict = regex_dict\n",
    "        self.districts = districts\n",
    "        self.verbose = verbose\n",
    "        self.wait = wait\n",
    "        self.file_districts = file_districts\n",
    "        self.file_flats = file_flats\n",
    "        self.dir_photo = dir_photo\n",
    "        self.district_columns = district_columns\n",
    "        self.flat_columns = flat_columns\n",
    "        \n",
    "        self.dir_district = None\n",
    "                \n",
    "    # генератор основной ссылки на список квартир в районе\n",
    "    # на вход подается номер страницы, номер района, 9 признаков по количеству комнат\n",
    "    # возвращает текстовую переменную ссылки\n",
    "    def get_page(self, pagenum, district_id, room1, room2, room3, room4, room5, room6, room7, room8, room9):\n",
    "        page = 'https://www.cian.ru/cat.php?deal_type=sale&district%5B0%5D=' + str(district_id) + \\\n",
    "                '&engine_version=2&offer_type=flat&p=' + str(pagenum) + \\\n",
    "                '&region=1&room1=' + str(room1) + \\\n",
    "                '&room2=' + str(room2) + \\\n",
    "                '&room3=' + str(room3) + \\\n",
    "                '&room4=' + str(room4) + \\\n",
    "                '&room5=' + str(room5) + \\\n",
    "                '&room6=' + str(room6) + \\\n",
    "                '&room7=' + str(room7) + \\\n",
    "                '&room8=' + str(room8) + \\\n",
    "                '&room9=' + str(room9)\n",
    "        return page\n",
    "    \n",
    "    # загрузчик HTML-содержимого\n",
    "    # на вход подается ссылка на страницу\n",
    "    # возвращает BS-переменную с HTML-содержимым страницы\n",
    "    def get_soup(self, page):\n",
    "        time.sleep(self.wait)\n",
    "        soup = None\n",
    "        redirect_1page = 'offer_type=flat&p=1' \n",
    "        response = requests.get(page, allow_redirects=False)\n",
    "        if response.status_code != 200:\n",
    "            if (redirect_1page in response.url) & (redirect_1page not in page):\n",
    "                if self.verbose:\n",
    "                    print(f' {response.status_code}', end='')\n",
    "                soup = None\n",
    "            elif 'captcha' in response.url:\n",
    "                if self.verbose:\n",
    "                    print('c', end='')\n",
    "                time.sleep(360)\n",
    "                response = requests.get(page, allow_redirects=False)\n",
    "            else: \n",
    "                for i in range(10):\n",
    "                    time.sleep(self.wait * 10)\n",
    "                    response = requests.get(page, allow_redirects=False)\n",
    "                    if response.status_code == 200:\n",
    "                        break\n",
    "        if response.status_code == 200:\n",
    "            html = response.content\n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "        return soup\n",
    "\n",
    "    # загрузчик датасета\n",
    "    # на вход подается название файла, из которого он будет загружен, \n",
    "    # и список его столбцов, в случае если датасет еще не создан\n",
    "    # возвращает датасет и список содержимого колонки id в нем\n",
    "    def load_df(self, my_file, columns):\n",
    "        my_path = Path(my_file)\n",
    "        if my_path.is_file():\n",
    "            df = pd.read_csv(my_file)\n",
    "            ids = list(df.id)\n",
    "        else:\n",
    "            df = pd.DataFrame(columns=columns)\n",
    "            ids = []\n",
    "        return df, ids\n",
    "\n",
    "    # сохраняет датасет\n",
    "    # на вход подается датасет и название файла, в который он будет сохранен\n",
    "    # ничего не возвращает\n",
    "    def save_df(self, df, my_file):\n",
    "        if df.shape[0] > 0:\n",
    "            df.to_csv(my_file, index=False)\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print('No rows in df!')  \n",
    "       \n",
    "    # на вход подается js-дамп текста по конкретному объявлению, id объявления\n",
    "    # ничего не возвращает, но ищет и сохраняет в отдельную папку все фотографии в данном объявлении     \n",
    "    def get_photo(self, data, cianId):\n",
    "        matches = self.get_matches(data, self.regex_dict['photoUrl'])\n",
    "        matches = [item for item in matches if item.endswith('-2.jpg')]\n",
    "        if matches:\n",
    "            dir_flat = f'{self.dir_district}/{cianId}'\n",
    "            if not os.path.exists(dir_flat):\n",
    "                 os.mkdir(dir_flat)\n",
    "            for i, url in zip(range(len(matches)), matches):\n",
    "                url = url.replace(\"\\\\u002F\", '/')\n",
    "#                 urllib.request.urlretrieve(url, str(f\"{dir_flat_photo}\\\\{cianId}_{i}.jpg\"))\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(url, str(f\"{dir_flat}/{cianId}_{i}.jpg\"))\n",
    "                except:\n",
    "                    print('p', end='')\n",
    "\n",
    "    # основной метод, вызываемый для поиска и парсинга объявлений\n",
    "    # на вход подается 9 признаков по количеству комнат\n",
    "    # ничего не возвращает   \n",
    "    def main(self, room1=0, room2=0, room3=0, room4=0, room5=0, room6=0, room7=0, room8=0, room9=0):\n",
    "        # логирование\n",
    "        if self.verbose:\n",
    "            print('ПАРСЕР КВАРТИР С САЙТА CIAN.RU')\n",
    "            print(f'Интервал между запросами: {self.wait} сек.')  \n",
    "        \n",
    "        # поиск квартир по всем районам\n",
    "        for district_id in self.districts: \n",
    "            self.parsing(district_id, room1, room2, room3, room4, room5, room6, room7, room8, room9)\n",
    "\n",
    "            \n",
    "    # метод, вызываемый для js-дампа по регулярному выражению\n",
    "    # на вход подается BS-содержимое и регулярное выражение\n",
    "    # возвращает текст js-дампа со всеми js-переменными по объявлениям на странице\n",
    "    def get_scriptData(self, soup, regex):\n",
    "        script = None\n",
    "        pattern = re.compile(r\"%s\" % regex)\n",
    "        script = soup.find(\"script\", text=pattern)\n",
    "        if script:\n",
    "            script = script.text.replace('{', '').replace('}', '')\n",
    "        return script\n",
    "\n",
    "    # на вход подается js-дамп и регулярное выражение\n",
    "    # возвращает id предложения  по регулярному выражению\n",
    "    def get_id(self, data):\n",
    "        match = None\n",
    "        pattern = re.compile(r\"(?<=ru\\\\u002Fsale\\\\u002Fflat\\\\u002F)(.*?)(?=\\\\u002F\\\",)\")\n",
    "        match = re.search(pattern, data)\n",
    "        if match:\n",
    "            match = match.group(1)\n",
    "        return match\n",
    "    \n",
    "    # метод, который находит 1 матч по регулярному выражению\n",
    "    # на вход подается js-дамп и регулярное выражение\n",
    "    # возвращает 1 матч  по регулярному выражению\n",
    "    def get_match(self, data, regex):\n",
    "        match = None\n",
    "        pattern = re.compile(r\"%s\" % regex)\n",
    "        match = re.search(pattern, data)\n",
    "        if match:\n",
    "            match = match.group(1)\n",
    "        return match\n",
    "    \n",
    "    # метод, который находит все матчи по регулярному выражению\n",
    "    # на вход подается js-дамп и регулярное выражение\n",
    "    # возвращает список матчей по регулярному выражению\n",
    "    def get_matches(self, data, regex):\n",
    "        matches = None\n",
    "        pattern = re.compile(r\"%s\" % regex)\n",
    "        matches = re.findall(pattern, data)\n",
    "        return matches\n",
    "    \n",
    "    # метод, который находит все js-дампы объявлений\n",
    "    # на вход подается js-дамп\n",
    "    # возвращает список js-дампов объявлений\n",
    "    def get_offersData(self, data):\n",
    "        offersData = None\n",
    "        match = self.get_match(data, self.regex_dict['offersData'])\n",
    "        if match:\n",
    "            offersData = match.split('siteBlockId')[:-1]\n",
    "        return offersData\n",
    "    \n",
    "    # находит три ближайших станции метро\n",
    "    # возвращает списки с названиями станций, временем в пути до них, типом передвижения\n",
    "    def get_underground(self, soup):\n",
    "        station_name = [None, None, None]\n",
    "        transportType = [None, None, None]\n",
    "        transport_time = [None, None, None]\n",
    "\n",
    "        match = self.get_match(soup, self.regex_dict['undergrounds'])\n",
    "        station_names = self.get_matches(match, self.regex_dict['station_name'])\n",
    "        transportTypes = self.get_matches(match, self.regex_dict['transportType'])\n",
    "        transport_times = self.get_matches(match, self.regex_dict['transport_time'])\n",
    "        if station_names:\n",
    "            for i in range(len(station_names)):\n",
    "                station_name[i] = station_names[i]\n",
    "        if transportTypes:\n",
    "            for i in range(len(transportTypes)):\n",
    "                transportType[i] = transportTypes[i]\n",
    "        if transport_times:\n",
    "            for i in range(len(transport_times)):\n",
    "                transport_time[i] = transport_times[i]\n",
    "\n",
    "        return station_name[0], station_name[1], station_name[2], \\\n",
    "                transportType[0], transportType[1], transportType[2], \\\n",
    "                transport_time[0], transport_time[1], transport_time[2]\n",
    "        \n",
    "    # парсер страниц\n",
    "    # на вход подается номер страницы, номер района, 9 признаков по количеству комнат\n",
    "    # ничего не возвращает, но сохраняет все найденные объявления в датасет с данными по квартирам\n",
    "    def parsing(self, district_id, room1, room2, room3, room4, room5, room6, room7, room8, room9):\n",
    "        \n",
    "        OFFERS_ON_PAGE = 28\n",
    "        self.dir_district = f'{self.dir_photo}/{district_id}'\n",
    "        if not os.path.exists(self.dir_district):\n",
    "            os.mkdir(self.dir_district)\n",
    "            \n",
    "        page1 = self.get_page(1, district_id, room1, room2, room3, room4, room5, room6, room7, room8, room9)\n",
    "        soup1 = self.get_soup(page1)\n",
    "        if soup1:\n",
    "            script = self.get_scriptData(soup1, self.regex_dict['offersData'])\n",
    "            totalOffers = self.get_match(script, self.regex_dict['totalOffers'])\n",
    "        else:\n",
    "            totalOffers = None\n",
    "        \n",
    "        df, ids = self.load_df(self.file_flats, self.flat_columns)\n",
    "        if totalOffers:\n",
    "            maxpage = math.ceil(float(totalOffers) / OFFERS_ON_PAGE) + 1\n",
    "            # логирование\n",
    "            if self.verbose:\n",
    "                print(f'Dstr:{district_id} |Offr:{totalOffers} |Pgs:{maxpage-1} [', end='')    \n",
    "            \n",
    "            newflat_cnt = 0\n",
    "            for i in range(1, maxpage):\n",
    "                # логирование\n",
    "                if self.verbose:\n",
    "                    print('.', end='')\n",
    "                page = self.get_page(i, district_id, room1, room2, room3, room4, room5, room6, room7, room8, room9)\n",
    "                soup = self.get_soup(page)\n",
    "                if soup:\n",
    "                    script = self.get_scriptData(soup, self.regex_dict['offersData'])\n",
    "                    offersData = self.get_offersData(script)   \n",
    "                    if offersData:\n",
    "                        for data in offersData:\n",
    "                            curr_id = self.get_id(data)\n",
    "                            if curr_id:\n",
    "                                if int(curr_id) not in ids:\n",
    "                                    newflat_cnt += 1\n",
    "                                    data_dict = {}\n",
    "                                    data_dict['id'] = curr_id\n",
    "                                    data_dict['url'] = f'https://www.cian.ru/sale/flat/{curr_id}/'\n",
    "                                    data_dict['timestamp_parsed'] = time.time()\n",
    "\n",
    "                                    self.get_photo(data, data_dict['id'])\n",
    "\n",
    "                                    data_dict['description'] = self.get_match(data, self.regex_dict['description'])\n",
    "                                    data_dict['total_area'] = self.get_match(data, self.regex_dict['totalArea'])\n",
    "                                    data_dict['loggias_count'] = self.get_match(data, self.regex_dict['loggiasCount'])\n",
    "                                    data_dict['flat_type'] = self.get_match(data, self.regex_dict['flatType'])\n",
    "                                    data_dict['kitchen_area'] = self.get_match(data, self.regex_dict['kitchenArea'])\n",
    "                                    data_dict['station_name1'], data_dict['station_name2'], data_dict['station_name3'], \\\n",
    "                                    data_dict['transport_type1'], data_dict['transport_type2'], data_dict['transport_type3'], \\\n",
    "                                    data_dict['transport_time1'], data_dict['transport_time2'], data_dict['transport_time3']  \\\n",
    "                                    = self.get_underground(data)\n",
    "                                    data_dict['coord_lat'] = self.get_match(data, self.regex_dict['coord_lat'])\n",
    "                                    data_dict['coord_lng'] = self.get_match(data, self.regex_dict['coord_lng'])\n",
    "                                    data_dict['location'] = self.get_match(data, self.regex_dict['location'])\n",
    "                                    data_dict['okrug'] = self.get_match(data, self.regex_dict['okrug'])\n",
    "                                    data_dict['raion'] = self.get_match(data, self.regex_dict['raion'])\n",
    "                                    data_dict['street'] = self.get_match(data, self.regex_dict['street'])\n",
    "                                    data_dict['house'] = self.get_match(data, self.regex_dict['house'])\n",
    "                                    data_dict['is_apartments'] = self.get_match(data, self.regex_dict['isApartments'])\n",
    "                                    data_dict['creation_date'] = self.get_match(data, self.regex_dict['creationDate'])\n",
    "                                    data_dict['status'] = self.get_match(data, self.regex_dict['status'])\n",
    "                                    data_dict['floor_number'] = self.get_match(data, self.regex_dict['floorNumber'])\n",
    "                                    data_dict['added_timestamp'] = self.get_match(data, self.regex_dict['addedTimestamp'])\n",
    "                                    data_dict['living_area'] = self.get_match(data, self.regex_dict['livingArea'])\n",
    "                                    data_dict['material_type'] = self.get_match(data, self.regex_dict['materialType'])\n",
    "                                    data_dict['build_year'] = self.get_match(data, self.regex_dict['buildYear'])\n",
    "                                    data_dict['passenger_lifts_count'] = self.get_match(data, self.regex_dict['passengerLiftsCount'])\n",
    "                                    data_dict['floors_count'] = self.get_match(data, self.regex_dict['floorsCount'])\n",
    "                                    data_dict['year'] = self.get_match(data, self.regex_dict['year'])\n",
    "                                    data_dict['is_complete'] = self.get_match(data, self.regex_dict['isComplete'])                           \n",
    "                                    data_dict['cargo_lifts_count'] = self.get_match(data, self.regex_dict['cargoLiftsCount'])\n",
    "                                    data_dict['rooms_count'] = self.get_match(data, self.regex_dict['roomsCount'])\n",
    "                                    data_dict['price'] = self.get_match(data, self.regex_dict['price'])\n",
    "                                    data_dict['mortgage_allowed'] = self.get_match(data, self.regex_dict['mortgageAllowed'])\n",
    "                                    data_dict['currency'] = self.get_match(data, self.regex_dict['currency'])\n",
    "                                    data_dict['account_type'] = self.get_match(data, self.regex_dict['accountType'])\n",
    "                                    data_dict['agency_name'] = self.get_match(data, self.regex_dict['agencyName'])\n",
    "                                    data_dict['cian_profile_status'] = self.get_match(data, self.regex_dict['cianProfileStatus'])\n",
    "                                    data_dict['cian_user_id'] = self.get_match(data, self.regex_dict['cianUserId'])\n",
    "                                    data_dict['company_name'] = self.get_match(data, self.regex_dict['companyName'])\n",
    "                                    data_dict['is_agent'] = self.get_match(data, self.regex_dict['isAgent'])\n",
    "                                    data_dict['is_builder'] = self.get_match(data, self.regex_dict['isBuilder'])\n",
    "                                    data_dict['is_passport_verified'] = self.get_match(data, self.regex_dict['isPassportVerified'])\n",
    "                                    data_dict['is_self_employed'] = self.get_match(data, self.regex_dict['isSelfEmployed'])\n",
    "                                    data_dict['is_sub_agent'] = self.get_match(data, self.regex_dict['isSubAgent'])\n",
    "                                    data_dict['user_trust_level'] = self.get_match(data, self.regex_dict['userTrustLevel'])\n",
    "                                    data_dict['user_id'] = self.get_match(data, self.regex_dict['userId'])\n",
    "                                    data_dict['user_type'] = self.get_match(data, self.regex_dict['userType'])\n",
    "                                    data_dict['is_cian_partner'] = self.get_match(data, self.regex_dict['isCianPartner'])\n",
    "                                    data_dict['user_address'] = self.get_match(data, self.regex_dict['userInput'])\n",
    "                                    \n",
    "                                    df = df.append(pd.Series(data_dict), ignore_index=True)\n",
    "                                    ids.append(int(curr_id))\n",
    "#                         self.save_df(df, self.file_flats)\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "            # логирование\n",
    "            if self.verbose:\n",
    "                print(f'] {newflat_cnt} found!')\n",
    "        else:\n",
    "            print(f'No offers in {district_id}!')\n",
    "        self.save_df(df, self.file_flats)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экземпляр класса CianParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cian_parser = CianParser(regex_dict=regex_dict, wait=3, districts=list(districts_dict.values()))\n",
    "# cian_parser = CianParser(regex_dict=regex_dict, wait=3, districts=[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск и парсинг объявлений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ПАРСЕР КВАРТИР С САЙТА CIAN.RU\n",
      "Интервал между запросами: 3 сек.\n",
      "Dstr:328 |Offr:899 |Pgs:33 [...............p............] 448 found!\n",
      "Dstr:327 |Offr:134 |Pgs:5 [.....] 117 found!\n",
      "Dstr:329 |Offr:868 |Pgs:31 [...........................] 264 found!\n",
      "Dstr:330 |Offr:43 |Pgs:2 [..] 40 found!\n",
      "Dstr:238 |Offr:399 |Pgs:15 [........] 195 found!\n",
      "Dstr:332 |Offr:2086 |Pgs:75 [.........] 118 found!\n",
      "Dstr:333 |Offr:33 |Pgs:2 [..] 32 found!\n",
      "Dstr:334 |Offr:923 |Pgs:33 [...........................] 216 found!\n",
      "Dstr:335 |Offr:4843 |Pgs:173 [.......ppppppppppppppppppp.p..........] 285 found!\n",
      "No offers in 336!\n",
      "Dstr:337 |Offr:233 |Pgs:9 [.........] 180 found!\n",
      "Dstr:338 |Offr:5 |Pgs:1 [.] 0 found!\n",
      "Dstr:339 |Offr:12 |Pgs:1 [.] 1 found!\n",
      "Dstr:340 |Offr:22 |Pgs:1 [.] 1 found!\n",
      "Dstr:341 |Offr:18 |Pgs:1 [.] 1 found!\n",
      "Dstr:342 |Offr:9 |Pgs:1 [.] 1 found!\n",
      "Dstr:343 |Offr:148 |Pgs:6 [......] 3 found!\n",
      "Dstr:344 |Offr:145 |Pgs:6 [......] 18 found!\n",
      "Dstr:345 |Offr:31 |Pgs:2 [..] 3 found!\n",
      "Dstr:346 |Offr:128 |Pgs:5 [.....] 12 found!\n",
      "Dstr:347 |Offr:40 |Pgs:2 [..] 6 found!\n",
      "Dstr:154 |Offr:236 |Pgs:9 [.........] 9 found!\n",
      "Dstr:355 |Offr:74 |Pgs:3 [...] 6 found!\n",
      "Dstr:152 |Offr:0 |Pgs:0 [] 0 found!\n",
      "Dstr:153 |Offr:0 |Pgs:0 [] 0 found!\n",
      "Dstr:356 |Offr:57 |Pgs:3 [...] 1 found!\n",
      "Dstr:357 |Offr:47 |Pgs:2 [..] 2 found!\n",
      "Dstr:358 |Offr:32 |Pgs:2 [..] 1 found!\n",
      "Dstr:125 |Offr:151 |Pgs:6 [......] 138 found!\n",
      "Dstr:126 |Offr:523 |Pgs:19 [......ppp.............] 327 found!\n",
      "Dstr:127 |Offr:1202 |Pgs:43 [...........................] 286 found!\n",
      "Dstr:128 |Offr:200 |Pgs:8 [........] 158 found!\n",
      "Dstr:129 |Offr:231 |Pgs:9 [.........] 190 found!\n",
      "Dstr:130 |Offr:2673 |Pgs:96 [.........................] 118 found!\n",
      "Dstr:131 |Offr:945 |Pgs:34 [.............] 126 found!\n",
      "Dstr:132 |Offr:197 |Pgs:8 [........] 175 found!\n",
      "Dstr:112 |Offr:28 |Pgs:1 [.] 0 found!\n",
      "Dstr:113 |Offr:903 |Pgs:33 [...........................] 147 found!\n",
      "Dstr:114 |Offr:513 |Pgs:19 [...................] 80 found!\n",
      "Dstr:115 |Offr:1086 |Pgs:39 [...........p...................] 198 found!\n",
      "Dstr:116 |Offr:1291 |Pgs:47 [.............] 185 found!\n",
      "Dstr:117 |Offr:349 |Pgs:13 [.....ppppp........] 210 found!\n",
      "Dstr:118 |Offr:993 |Pgs:36 [..........................] 483 found!\n",
      "Dstr:119 |Offr:385 |Pgs:14 [.......pp.......] 316 found!\n",
      "Dstr:120 |Offr:3614 |Pgs:130 [........................................] 461 found!\n",
      "Dstr:121 |Offr:735 |Pgs:27 [.......pppppppppp..........ppppp..........] 464 found!\n",
      "Dstr:122 |Offr:822 |Pgs:30 [......pp......................] 597 found!\n",
      "Dstr:123 |Offr:1060 |Pgs:38 [..........................] 576 found!\n",
      "Dstr:124 |Offr:396 |Pgs:15 [.....ppppp..p........] 296 found!\n",
      "Dstr:349 |Offr:0 |Pgs:0 [] 0 found!\n",
      "Dstr:348 |Offr:0 |Pgs:0 [] 0 found!\n",
      "Dstr:350 |Offr:0 |Pgs:0 [] 0 found!\n",
      "Dstr:100 |Offr:505 |Pgs:19 [...................] 78 found!\n",
      "Dstr:101 |Offr:330 |Pgs:12 [............] 44 found!\n",
      "Dstr:102 |Offr:264 |Pgs:10 [..........] 40 found!\n",
      "Dstr:103 |Offr:338 |Pgs:13 [.............] 39 found!\n",
      "Dstr:104 |Offr:162 |Pgs:6 [......] 11 found!\n",
      "Dstr:105 |Offr:414 |Pgs:15 [...............] 50 found!\n",
      "Dstr:106 |Offr:850 |Pgs:31 [..........................] 95 found!\n",
      "Dstr:107 |Offr:200 |Pgs:8 [........] 13 found!\n",
      "Dstr:108 |Offr:328 |Pgs:12 [.....ppppp.......] 59 found!\n",
      "Dstr:109 |Offr:701 |Pgs:26 [..........................] 32 found!\n",
      "Dstr:110 |Offr:910 |Pgs:33 [...........................] 65 found!\n",
      "Dstr:111 |Offr:293 |Pgs:11 [...........] 23 found!\n",
      "Dstr:23 |Offr:813 |Pgs:30 [...........................] 342 found!\n",
      "Dstr:24 |Offr:1616 |Pgs:58 [.................] 147 found!\n",
      "Dstr:25 |Offr:111 |Pgs:4 [....] 24 found!\n",
      "Dstr:26 |Offr:404 |Pgs:15 [...............] 22 found!\n",
      "Dstr:27 |Offr:144 |Pgs:6 [......] 100 found!\n",
      "Dstr:28 |Offr:441 |Pgs:16 [................] 28 found!\n",
      "Dstr:29 |Offr:507 |Pgs:19 [...................] 17 found!\n",
      "Dstr:30 |Offr:974 |Pgs:35 [...........................] 68 found!\n",
      "Dstr:31 |Offr:203 |Pgs:8 [........] 19 found!\n",
      "Dstr:32 |Offr:289 |Pgs:11 [...........] 23 found!\n",
      "Dstr:33 |Offr:22 |Pgs:1 [.] 0 found!\n",
      "Dstr:34 |Offr:250 |Pgs:9 [.........] 16 found!\n",
      "Dstr:35 |Offr:189 |Pgs:7 [.......] 24 found!\n",
      "Dstr:36 |Offr:374 |Pgs:14 [..............] 59 found!\n",
      "Dstr:37 |Offr:763 |Pgs:28 [...........................] 218 found!\n",
      "Dstr:38 |Offr:1633 |Pgs:59 [..................................p....] 479 found!\n",
      "Dstr:13 |Offr:1130 |Pgs:41 [.......................................] 9 found!\n",
      "Dstr:14 |Offr:1465 |Pgs:53 [.................] 58 found!\n",
      "Dstr:15 |Offr:757 |Pgs:28 [............................] 61 found!\n",
      "Dstr:16 |Offr:523 |Pgs:19 [..................] 350 found!\n",
      "Dstr:17 |Offr:497 |Pgs:18 [..................] 28 found!\n",
      "Dstr:18 |Offr:4273 |Pgs:153 [..............................................] 217 found!\n",
      "Dstr:19 |Offr:694 |Pgs:25 [.........................] 128 found!\n",
      "Dstr:20 |Offr:1449 |Pgs:52 [....................................................] 193 found!\n",
      "Dstr:21 |Offr:2887 |Pgs:104 [..................................................] 382 found!\n",
      "Dstr:22 |Offr:721 |Pgs:26 [..................] 169 found!\n",
      "Dstr:84 |Offr:424 |Pgs:16 [................] 59 found!\n",
      "Dstr:85 |Offr:105 |Pgs:4 [....] 9 found!\n",
      "Dstr:86 |Offr:149 |Pgs:6 [......] 17 found!\n",
      "Dstr:87 |Offr:2710 |Pgs:97 [..............] 56 found!\n",
      "Dstr:88 |Offr:536 |Pgs:20 [....................] 159 found!\n",
      "Dstr:89 |Offr:284 |Pgs:11 [...........] 40 found!\n",
      "Dstr:90 |Offr:215 |Pgs:8 [........] 12 found!\n",
      "Dstr:91 |Offr:243 |Pgs:9 [.........] 36 found!\n",
      "Dstr:92 |Offr:247 |Pgs:9 [.........] 38 found!\n",
      "Dstr:93 |Offr:262 |Pgs:10 [..........] 24 found!\n",
      "Dstr:94 |Offr:188 |Pgs:7 [.......] 35 found!\n",
      "Dstr:95 |Offr:490 |Pgs:18 [..................] 53 found!\n",
      "Dstr:96 |Offr:185 |Pgs:7 [.......] 44 found!\n",
      "Dstr:97 |Offr:222 |Pgs:8 [.....pppppppp...] 18 found!\n",
      "Dstr:98 |Offr:206 |Pgs:8 [........] 3 found!\n",
      "Dstr:99 |Offr:422 |Pgs:16 [........ppp........] 49 found!\n",
      "Dstr:39 |Offr:972 |Pgs:35 [......] 50 found!\n",
      "Dstr:40 |Offr:129 |Pgs:5 [.....] 23 found!\n",
      "Dstr:41 |Offr:176 |Pgs:7 [.......] 14 found!\n",
      "Dstr:42 |Offr:233 |Pgs:9 [.........] 9 found!\n",
      "Dstr:43 |Offr:256 |Pgs:10 [..........] 36 found!\n",
      "Dstr:44 |Offr:852 |Pgs:31 [...........................] 22 found!\n",
      "Dstr:45 |Offr:830 |Pgs:30 [...........................] 71 found!\n",
      "Dstr:46 |Offr:173 |Pgs:7 [.......] 13 found!\n",
      "Dstr:47 |Offr:500 |Pgs:18 [..................] 29 found!\n",
      "Dstr:48 |Offr:1427 |Pgs:51 [...........................] 219 found!\n",
      "Dstr:49 |Offr:338 |Pgs:13 [.............] 13 found!\n",
      "Dstr:50 |Offr:556 |Pgs:20 [....................] 42 found!\n",
      "Dstr:51 |Offr:305 |Pgs:11 [...........] 18 found!\n",
      "Dstr:53 |Offr:171 |Pgs:7 [.......] 9 found!\n",
      "Dstr:52 |Offr:187 |Pgs:7 [.......] 11 found!\n",
      "Dstr:54 |Offr:234 |Pgs:9 [.........] 17 found!\n",
      "Dstr:55 |Offr:332 |Pgs:12 [............] 156 found!\n",
      "Dstr:56 |Offr:720 |Pgs:26 [..........................] 235 found!\n",
      "Dstr:57 |Offr:234 |Pgs:9 [.........] 30 found!\n",
      "Dstr:59 |Offr:127 |Pgs:5 [.....] 19 found!\n",
      "Dstr:58 |Offr:13 |Pgs:1 [.] 3 found!\n",
      "Dstr:60 |Offr:665 |Pgs:24 [........................] 211 found!\n",
      "Dstr:61 |Offr:171 |Pgs:7 [.......] 6 found!\n",
      "Dstr:62 |Offr:372 |Pgs:14 [..............] 34 found!\n",
      "Dstr:63 |Offr:132 |Pgs:5 [.....] 6 found!\n",
      "Dstr:64 |Offr:393 |Pgs:15 [...............] 48 found!\n",
      "Dstr:65 |Offr:170 |Pgs:7 [.......] 5 found!\n",
      "Dstr:66 |Offr:119 |Pgs:5 [.....] 6 found!\n",
      "Dstr:67 |Offr:279 |Pgs:10 [..........] 32 found!\n",
      "Dstr:68 |Offr:199 |Pgs:8 [........] 20 found!\n",
      "Dstr:69 |Offr:150 |Pgs:6 [......] 8 found!\n",
      "Dstr:70 |Offr:314 |Pgs:12 [............] 21 found!\n",
      "Dstr:71 |Offr:295 |Pgs:11 [...........] 15 found!\n",
      "Dstr:72 |Offr:375 |Pgs:14 [..............] 287 found!\n",
      "Dstr:73 |Offr:54 |Pgs:2 [..] 11 found!\n",
      "Dstr:74 |Offr:310 |Pgs:12 [............] 36 found!\n",
      "Dstr:75 |Offr:988 |Pgs:36 [...........................] 39 found!\n",
      "Dstr:76 |Offr:926 |Pgs:34 [...........................] 63 found!\n",
      "Dstr:77 |Offr:718 |Pgs:26 [..........................] 151 found!\n",
      "Dstr:78 |Offr:1301 |Pgs:47 [..................................] 109 found!\n",
      "Dstr:79 |Offr:147 |Pgs:6 [......] 25 found!\n",
      "Dstr:80 |Offr:174 |Pgs:7 [.pppppppppp......] 9 found!\n",
      "Dstr:81 |Offr:2090 |Pgs:75 [...........................] 300 found!\n",
      "Dstr:82 |Offr:303 |Pgs:11 [...........] 14 found!\n",
      "Dstr:83 |Offr:637 |Pgs:23 [.......................] 226 found!\n"
     ]
    }
   ],
   "source": [
    "cian_parser.main(room1=1, room2=1, room3=1, room4=1, room5=1, room6=1, room7=1, room8=1, room9=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
